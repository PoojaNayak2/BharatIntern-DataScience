{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D-YFUl4KjC5"
      },
      "source": [
        "Created a Kaggle directory (~/.kaggle) and copied my Kaggle API key file (kaggle.json) into this directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ltXgmnE_AjI"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzDgtSgZLWCR"
      },
      "outputs": [],
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ClW9qdK7x5"
      },
      "source": [
        "Since the dataset is a huge file we can use the Kaggle API key to download the complete dataset here directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X_f4W_RE7gi",
        "outputId": "fe4a96f5-b4dd-4400-bdd5-1b532a5d8cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dogs-vs-cats.zip to /content\n",
            "100% 1.06G/1.06G [00:37<00:00, 32.8MB/s]\n",
            "100% 1.06G/1.06G [00:37<00:00, 30.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7guTl7hBN2hK"
      },
      "source": [
        "extracting contents of the zipped file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRq_DVNNp7T-"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLjhKoPuqLL1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfeXVdfrOZxi"
      },
      "source": [
        "\n",
        "*   Generators in Keras are Python iterators that yield batches of data during training instead of loading the entire dataset into memory at once.\n",
        "\n",
        "*   the image_datsets_from_directory in keras is used to create the training and validation datasets from image directories.Further all images are resized into a uniform pixel size of 256x256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f2dkRxXqobD",
        "outputId": "3cc94c14-a738-461c-e848-2e35fe0d78e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-8cFc2nPv_9"
      },
      "source": [
        "We carry out normalization since the images in the dataset are in the pixel range of 0-255 we need to bring it down to the range of 0-1 for better evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2H94lUTyr_Rd"
      },
      "outputs": [],
      "source": [
        "def process(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obsNh6WGd9Ko"
      },
      "source": [
        "# 3 layer CNN model\n",
        "Summary of the architecture:\n",
        "*   Three sets of Convolutional Layers, each followed by Batch Normalization and MaxPooling2D.\n",
        "*   Flatten layer to transition from convolutional layers to dense layers.\n",
        "*   Two Dense (Fully Connected) Layers with ReLU activation and dropout for regularization.\n",
        "*   Output layer with a single neuron and sigmoid activation for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FcGcmkescVi"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First Convolutional Layer\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "# Second Convolutional Layer\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "# Third Convolutional Layer\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "\n",
        "# Flatten layer to transition from convolutional layers to dense layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense (Fully Connected) Layers\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aJZyq2Ltdno",
        "outputId": "dc6715c5-124a-4522-efe2-d3e91ca7a513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 254, 254, 32)      128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 125, 125, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 60, 60, 128)       512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14848193 (56.64 MB)\n",
            "Trainable params: 14847745 (56.64 MB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUqGk1kwhHzq"
      },
      "source": [
        "# Model Compilation\n",
        "1. Optimizer ('adam'): The Adam optimizer adapts to the learning rates during training.\n",
        "\n",
        "2. Loss ('binary_crossentropy'): Binary crossentropy is a suitable loss function for binary classification problems. It measures the difference between the true labels and the predicted probabilities.\n",
        "\n",
        "3. Metrics (['accuracy']): the accuracy metric to evaluate how well your model is performing on the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL-E5k_5tf9N"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHBFNFHCtzLu",
        "outputId": "d985fc8f-4e99-4af1-c1d3-00d74e35a861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 4062s 6s/step - loss: 1.3583 - accuracy: 0.5624 - val_loss: 0.6756 - val_accuracy: 0.5974\n",
            "Epoch 2/10\n",
            "215/625 [=========>....................] - ETA: 41:09 - loss: 0.6710 - accuracy: 0.6062"
          ]
        }
      ],
      "source": [
        "result = model.fit(train_ds,epochs=10,validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLBW_tXylzkO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EjCTVt4nYbp"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzXQQAoKrvnT"
      },
      "source": [
        "(Open-source computer vision) OpenCV and image processing library is used for image processing tasks such as reading and displaying images, resizing, applying filters, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4qNNsN28GTc"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU3N6vPQ8z_t"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.imread('/content/dog.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsiIWUQO88TH"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-IOidqx8_wv"
      },
      "outputs": [],
      "source": [
        "test_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbhZpyb29OPB"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.resize(test_img,(256,256))\n",
        "test_input = test_img.reshape((1,256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syGMbjmU9grR"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRkIkniZ9mOI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}